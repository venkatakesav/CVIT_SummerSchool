{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "05dcb1f21f9746ea8367494ce9d42f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ebdad85f47642b6ad3b08f08858677b",
              "IPY_MODEL_537e98be367c40898dd99232c0ef9149"
            ],
            "layout": "IPY_MODEL_af7399af35cf4f44aed5fad8744243c2"
          }
        },
        "8ebdad85f47642b6ad3b08f08858677b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec17383bcc574ff78a3c99f32a08617d",
            "placeholder": "​",
            "style": "IPY_MODEL_6d345c46c8114972b5cd66eaacb17fdb",
            "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "537e98be367c40898dd99232c0ef9149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a90ee45225840db82bc3b6e74667772",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3a0661fdf80c44f3b8790ea31aa3834e",
            "value": 1
          }
        },
        "af7399af35cf4f44aed5fad8744243c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec17383bcc574ff78a3c99f32a08617d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d345c46c8114972b5cd66eaacb17fdb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a90ee45225840db82bc3b6e74667772": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a0661fdf80c44f3b8790ea31aa3834e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raviteja654321/CVIT_Workshop/blob/main/Day_6/Day_6_wandb_demo_HandsOn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using wandb to track experiments.\n",
        "\n",
        "Demo task: multi-class image classification using CIFAR10 dataset."
      ],
      "metadata": {
        "id": "h6hjehhHW4tC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import average_precision_score\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models\n",
        "from torchvision import transforms as T\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "!pip install wandb\n",
        "\n",
        "!wandb.login()\n"
      ],
      "metadata": {
        "id": "OUnLA0ASMK4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e94c708-896b-465a-8000-d67f0115681d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.31)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.24.0)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
            "/bin/bash: -c: line 1: syntax error: unexpected end of file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The next cell includes-\n",
        "- Collecting the CIFAR10 dataset and defining data loaders.\n",
        "- Methods to load model, criterion, optimizer and schedulers.\n",
        "- Definition of AverageMeter"
      ],
      "metadata": {
        "id": "s8hEreACXETi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Downloading CIFAR10 dataset\n",
        "inp_transforms = T.Compose([T.ToTensor(),\n",
        "                            T.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                        std=[0.229, 0.224, 0.225])])\n",
        "tgt_transforms = T.Lambda(lambda y: torch.zeros(10, dtype=torch.long).scatter_(0, torch.tensor(y), value=1))\n",
        "cifar10 = datasets.CIFAR10(root = \"/.\",\n",
        "                           transform = inp_transforms,\n",
        "                           target_transform = tgt_transforms,\n",
        "                           download = True)\n",
        "\n",
        "# Defining dataset split (80-20)\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(cifar10,\n",
        "                                                           [int(len(cifar10)*0.80), int(len(cifar10)*0.20)])\n",
        "\n",
        "# Defining the dataloaders\n",
        "train_dataloader = DataLoader(train_dataset,\n",
        "                              batch_size=200,\n",
        "                              shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset,\n",
        "                            batch_size=200,\n",
        "                            shuffle=False)\n",
        "\n",
        "\n",
        "# Method to get model based on config param model_type\n",
        "def get_model(model_type):\n",
        "    model = None\n",
        "    if model_type == \"pretrained\": # Loading pretrained ResNet18 and with updated to final fc layer. \n",
        "        model = models.resnet18(pretrained=True)\n",
        "        model.fc = nn.Linear(512, 10)\n",
        "        model = model.to(device)\n",
        "    elif model_type == \"scratch\": # Loading a blank ResNet18 which generated 10 outputs.\n",
        "        model = models.resnet18(num_classes=10)\n",
        "        model = model.to(device)\n",
        "    else:\n",
        "        raise NotImplemented\n",
        "    return model\n",
        "\n",
        "\n",
        "# Method to get criterion, optimizer and scheduler based on config params.\n",
        "def get_criterion_optimizer_scheduler(config, model):\n",
        "    optim_dct = {\n",
        "        \"adam\": optim.Adam,\n",
        "        \"SGD\": optim.SGD,\n",
        "        \"RMSprop\": optim.RMSprop\n",
        "    }\n",
        "    optimizer = optim_dct[config[\"optimizer\"]](model.parameters(), lr=config[\"lr\"])\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                           factor=0.1,\n",
        "                                                           patience=config[\"scheduler_patience\"],\n",
        "                                                           threshold=config[\"scheduler_thresh\"])\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    return criterion, optimizer, scheduler\n",
        "\n",
        "\n",
        "\n",
        "# Remainder of this cell includes definition of AverageMeter (can be ignored)\n",
        "\"\"\"\n",
        "Code taken from Pytorch ImageNet examples\n",
        "https://github.com/pytorch/examples/blob/main/imagenet/main.py#L375\n",
        "\"\"\"\n",
        "class Summary():\n",
        "    NONE = 0\n",
        "    AVERAGE = 1\n",
        "    SUM = 2\n",
        "    COUNT = 3\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self, name, fmt=':f', summary_type=Summary.AVERAGE):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.summary_type = summary_type\n",
        "        self.val_history = list()\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "        self.val_history = list()\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "        self.val_history.append(val)\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "    \n",
        "    def summary(self):\n",
        "        fmtstr = ''\n",
        "        if self.summary_type is Summary.NONE:\n",
        "            fmtstr = ''\n",
        "        elif self.summary_type is Summary.AVERAGE:\n",
        "            fmtstr = '{name} {avg:.3f}'\n",
        "        elif self.summary_type is Summary.SUM:\n",
        "            fmtstr = '{name} {sum:.3f}'\n",
        "        elif self.summary_type is Summary.COUNT:\n",
        "            fmtstr = '{name} {count:.3f}'\n",
        "        else:\n",
        "            raise ValueError('invalid summary type %r' % self.summary_type)        \n",
        "        return fmtstr.format(**self.__dict__)\n"
      ],
      "metadata": {
        "id": "N0IyFq2jMUTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ad04abb-f5fd-43ec-ca43-142740e2f6a9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Following cell includes-\n",
        "- Defining the train and eval loops.\n",
        "- Method to trigger training loops based on config parameters."
      ],
      "metadata": {
        "id": "UIEngQlXXfi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nxAgaicWXRb",
        "outputId": "4dfe5e6a-52a6-4ba7-d1ad-c941958d1ca2"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mraviteja_6\u001b[0m (\u001b[33mcvit_work\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The train function without wandb logging\n",
        "\n",
        "def train(model, criterion, optimizer, scheduler, epochs, train_dataloader, val_dataloader, device):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        loss_meter = AverageMeter(\"train_loss\", \":.5f\")\n",
        "        epoch_outs, epoch_tgt = list(), list()\n",
        "        for data, tgt_vec in tqdm(train_dataloader):\n",
        "            data, tgt_vec = data.to(device), tgt_vec.to(device)\n",
        "            targets = torch.argmax(tgt_vec, axis=1)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(data)\n",
        "            loss = criterion(out, targets)\n",
        "            loss_meter.update(loss.item(), data.shape[0])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_outs.append(out)\n",
        "            epoch_tgt.append(tgt_vec)\n",
        "        predictions = torch.vstack([torch.softmax(out, axis=1) for out in epoch_outs]).detach().cpu().numpy()\n",
        "        targets = torch.cat([tgt for tgt in epoch_tgt], dim=0).detach().cpu().numpy()\n",
        "        ap_score = average_precision_score(targets, predictions)\n",
        "        eval_loss_meter, eval_ap_score = evaluate(model, criterion, val_dataloader, device)\n",
        "        data_to_log = {\n",
        "            \"epoch\": epoch+1,\n",
        "            \"train_loss\": loss_meter.avg,\n",
        "            \"eval_loss\": eval_loss_meter.avg,\n",
        "            \"train_ap_score\": ap_score,\n",
        "            \"eval_ap_score\": eval_ap_score,\n",
        "            \"lr\": optimizer.state_dict()[\"param_groups\"][0][\"lr\"],\n",
        "        }\n",
        "        scheduler.step(eval_loss_meter.avg)\n",
        "        print(data_to_log)\n",
        "        # wandb.log(data_to_log)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, criterion, val_dataloader, device):\n",
        "    model.eval()\n",
        "    loss_meter = AverageMeter(\"eval_loss\", \":.5f\")\n",
        "    epoch_outs, epoch_tgt = list(), list()\n",
        "    for data, tgt_vec in val_dataloader:\n",
        "        data, tgt_vec = data.to(device), tgt_vec.to(device)\n",
        "        targets = torch.argmax(tgt_vec, axis=1)\n",
        "        out = model(data)\n",
        "        loss = criterion(out, targets)\n",
        "        loss_meter.update(loss.item(), data.shape[0])\n",
        "        epoch_outs.append(out)\n",
        "        epoch_tgt.append(tgt_vec)\n",
        "    predictions = torch.vstack([torch.softmax(out, axis=1) for out in epoch_outs]).detach().cpu().numpy()\n",
        "    targets = torch.cat([tgt for tgt in epoch_tgt], dim=0).detach().cpu().numpy()\n",
        "    ap_score = average_precision_score(targets, predictions)\n",
        "    return loss_meter, ap_score\n",
        "\n",
        "\n",
        "def trigger_training(config):\n",
        "    model = get_model(config[\"model_type\"])\n",
        "    criterion, optimizer, scheduler = get_criterion_optimizer_scheduler(config, model)\n",
        "    epochs = config[\"num_epochs\"]\n",
        "\n",
        "    train(model, criterion, optimizer, scheduler, epochs, train_dataloader, val_dataloader, device)\n"
      ],
      "metadata": {
        "id": "jfchRAmxMcoF"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complete the config file, edit the cells in this notebook to log data to wandb and trigger training loops!"
      ],
      "metadata": {
        "id": "Jtb0ll98YTB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill the Config file below and log the experiment at wandb\n",
        "config = {\n",
        "    \"lr\": 0.0, \n",
        "    \"model_type\": \"scratch\", # pretrained/scratch\n",
        "    \"optimizer\": \"adam\", # adam/SGD/RMSprop\n",
        "    \"criterion\": \"ce\",\n",
        "    \"scheduler_patience\": 3,\n",
        "    \"scheduler_thresh\": 0.001,\n",
        "    \"num_epochs\": 40, # CHANGE\n",
        "    \"gpu_id\": 0,\n",
        "    \"wandb_run_name\": \"ravi's_run\" ### FILL YOUR NAME HERE\n",
        "}\n"
      ],
      "metadata": {
        "id": "2XWOBnxhMkdl"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "BLGywkQ4NDMG"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RyGt96kZN60-"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0RfnKkXnN7Sd"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7XYU1R7SN7at"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1u1MT1lHN7id"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WandB Steps"
      ],
      "metadata": {
        "id": "4br2c7d1N8ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 1: Import WandB in your code\n",
        "\n",
        "import wandb\n",
        "\n",
        "### Step 1 ends"
      ],
      "metadata": {
        "id": "gg1VnOOBOAGe"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 2:\n",
        "# Initiate wandb in your script. The moment we trigger wandb.init(), an active\n",
        "# socket connection is established between your machine and wandb server.\n",
        "# We specify the entity (wandb username) and project (which wandb project to use for logging)\n",
        "\n",
        "wandb.init(entity = \"dhruv_sri\",   # wandb username. (NOT REQUIRED ARG. ANYMORE, it fetches from initial login)\n",
        "           project = \"wandb_demo\", # wandb project name. New project will be created if given project is missing.\n",
        "           config = config         # Config dict\n",
        "          )\n",
        "wandb.run.name = config[\"wandb_run_name\"]\n",
        "\n",
        "### Step 2 ends.\n"
      ],
      "metadata": {
        "id": "2oIAE7tpOBH_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "9868ec38-c27c-46cd-d498-239c83c7ce4d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:8l48fnii) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>eval_ap_score</td><td>▅▄▃█▁▅▇▆▅▅</td></tr><tr><td>eval_loss</td><td>▅▇▆▂▆▅█▂▂▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_ap_score</td><td>▆▂▅▅▁▁█▁█▂</td></tr><tr><td>train_loss</td><td>▄▆█▃▆▅▁▅▄▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>eval_ap_score</td><td>0.10031</td></tr><tr><td>eval_loss</td><td>2.53483</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>train_ap_score</td><td>0.10054</td></tr><tr><td>train_loss</td><td>2.53055</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">wandering-spaceship-9</strong> at: <a href='https://wandb.ai/dhruv_sri/wandb_demo/runs/8l48fnii' target=\"_blank\">https://wandb.ai/dhruv_sri/wandb_demo/runs/8l48fnii</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230527_092642-8l48fnii/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:8l48fnii). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230527_093047-09ddk26a</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/dhruv_sri/wandb_demo/runs/09ddk26a' target=\"_blank\">quiet-fog-13</a></strong> to <a href='https://wandb.ai/dhruv_sri/wandb_demo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/dhruv_sri/wandb_demo' target=\"_blank\">https://wandb.ai/dhruv_sri/wandb_demo</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/dhruv_sri/wandb_demo/runs/09ddk26a' target=\"_blank\">https://wandb.ai/dhruv_sri/wandb_demo/runs/09ddk26a</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 3: Trigger wandb log\n",
        "# The train function without wandb logging\n",
        "\n",
        "def train(model, criterion, optimizer, scheduler, epochs, train_dataloader, val_dataloader, device):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        loss_meter = AverageMeter(\"train_loss\", \":.5f\")\n",
        "        epoch_outs, epoch_tgt = list(), list()\n",
        "        for data, tgt_vec in tqdm(train_dataloader):\n",
        "            data, tgt_vec = data.to(device), tgt_vec.to(device)\n",
        "            targets = torch.argmax(tgt_vec, axis=1)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(data)\n",
        "            loss = criterion(out, targets)\n",
        "            loss_meter.update(loss.item(), data.shape[0])\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_outs.append(out)\n",
        "            epoch_tgt.append(tgt_vec)\n",
        "        predictions = torch.vstack([torch.softmax(out, axis=1) for out in epoch_outs]).detach().cpu().numpy()\n",
        "        targets = torch.cat([tgt for tgt in epoch_tgt], dim=0).detach().cpu().numpy()\n",
        "        ap_score = average_precision_score(targets, predictions)\n",
        "        eval_loss_meter, eval_ap_score = evaluate(model, criterion, val_dataloader, device)\n",
        "        data_to_log = {\n",
        "            \"epoch\": epoch+1,\n",
        "            \"train_loss\": loss_meter.avg,\n",
        "            \"eval_loss\": eval_loss_meter.avg,\n",
        "            \"train_ap_score\": ap_score,\n",
        "            \"eval_ap_score\": eval_ap_score,\n",
        "            \"lr\": optimizer.state_dict()[\"param_groups\"][0][\"lr\"],\n",
        "        }\n",
        "        scheduler.step(eval_loss_meter.avg)\n",
        "        print(data_to_log)\n",
        "        wandb.log(data_to_log)\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, criterion, val_dataloader, device):\n",
        "    model.eval()\n",
        "    loss_meter = AverageMeter(\"eval_loss\", \":.5f\")\n",
        "    epoch_outs, epoch_tgt = list(), list()\n",
        "    for data, tgt_vec in val_dataloader:\n",
        "        data, tgt_vec = data.to(device), tgt_vec.to(device)\n",
        "        targets = torch.argmax(tgt_vec, axis=1)\n",
        "        out = model(data)\n",
        "        loss = criterion(out, targets)\n",
        "        loss_meter.update(loss.item(), data.shape[0])\n",
        "        epoch_outs.append(out)\n",
        "        epoch_tgt.append(tgt_vec)\n",
        "    predictions = torch.vstack([torch.softmax(out, axis=1) for out in epoch_outs]).detach().cpu().numpy()\n",
        "    targets = torch.cat([tgt for tgt in epoch_tgt], dim=0).detach().cpu().numpy()\n",
        "    ap_score = average_precision_score(targets, predictions)\n",
        "    return loss_meter, ap_score\n",
        "\n",
        "\n",
        "def trigger_training(config):\n",
        "    model = get_model(config[\"model_type\"])\n",
        "    criterion, optimizer, scheduler = get_criterion_optimizer_scheduler(config, model)\n",
        "    epochs = config[\"num_epochs\"]\n",
        "\n",
        "    train(model, criterion, optimizer, scheduler, epochs, train_dataloader, val_dataloader, device)\n",
        "\n",
        "# This step is responsible for sending the logs to wandb\n",
        "# data_to_log = {\"epoch\": epoch, \"loss\": loss_value, \"accuracy\": accuracy_value}\n",
        "\n",
        "# wandb.log(data_to_log)\n",
        "trigger_training(config)\n",
        "### Step 3 ends.\n"
      ],
      "metadata": {
        "id": "P_c8_juPOC6o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0390bfc-bb7f-4123-fdcc-39062c6460c2"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:17<00:00, 11.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 1, 'train_loss': 2.4630929005146025, 'eval_loss': 2.447629451751709, 'train_ap_score': 0.1050948485159302, 'eval_ap_score': 0.10802666556809715, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:17<00:00, 11.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 2, 'train_loss': 2.463619065284729, 'eval_loss': 2.449119834899902, 'train_ap_score': 0.10491947021708939, 'eval_ap_score': 0.10795547850672346, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 11.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 3, 'train_loss': 2.463335483074188, 'eval_loss': 2.4474487257003785, 'train_ap_score': 0.10493462033789558, 'eval_ap_score': 0.10805936382399439, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:17<00:00, 11.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 4, 'train_loss': 2.4627153205871584, 'eval_loss': 2.4498410749435426, 'train_ap_score': 0.1049927181699011, 'eval_ap_score': 0.10815283059633651, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 11.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 5, 'train_loss': 2.4636375868320464, 'eval_loss': 2.4488751983642576, 'train_ap_score': 0.10503393871200131, 'eval_ap_score': 0.10831088732936076, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 12.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 6, 'train_loss': 2.463441170454025, 'eval_loss': 2.449700345993042, 'train_ap_score': 0.1050087542019599, 'eval_ap_score': 0.10798663858883546, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:17<00:00, 11.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 7, 'train_loss': 2.4620381915569305, 'eval_loss': 2.4553409910202024, 'train_ap_score': 0.10533666951780987, 'eval_ap_score': 0.10786828225030898, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 12.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 8, 'train_loss': 2.462830823659897, 'eval_loss': 2.451388368606567, 'train_ap_score': 0.10508876797302014, 'eval_ap_score': 0.10790572372535978, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:18<00:00, 10.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 9, 'train_loss': 2.4636482226848604, 'eval_loss': 2.4514273834228515, 'train_ap_score': 0.10493987934186003, 'eval_ap_score': 0.10815494860855088, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:18<00:00, 10.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 10, 'train_loss': 2.4647344267368316, 'eval_loss': 2.452953782081604, 'train_ap_score': 0.10479909518838357, 'eval_ap_score': 0.10789911600375512, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 12.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 11, 'train_loss': 2.46432128071785, 'eval_loss': 2.4497513914108278, 'train_ap_score': 0.10486832716277764, 'eval_ap_score': 0.10795454747893518, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:18<00:00, 11.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 12, 'train_loss': 2.462405964136124, 'eval_loss': 2.452073826789856, 'train_ap_score': 0.1051147288388371, 'eval_ap_score': 0.10800537293664533, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 12.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 13, 'train_loss': 2.4645602822303774, 'eval_loss': 2.4501070308685304, 'train_ap_score': 0.10471026093555065, 'eval_ap_score': 0.10826815619846078, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 11.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 14, 'train_loss': 2.463180202245712, 'eval_loss': 2.45191113948822, 'train_ap_score': 0.10494433816609097, 'eval_ap_score': 0.10811079863930668, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 12.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 15, 'train_loss': 2.4633521246910095, 'eval_loss': 2.4526393032073974, 'train_ap_score': 0.10515763870063574, 'eval_ap_score': 0.10819773051665971, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 12.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 16, 'train_loss': 2.4629261040687562, 'eval_loss': 2.4524674129486086, 'train_ap_score': 0.10504058690209975, 'eval_ap_score': 0.10753269858919527, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:17<00:00, 11.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 17, 'train_loss': 2.4634186923503876, 'eval_loss': 2.453853702545166, 'train_ap_score': 0.1050677407101103, 'eval_ap_score': 0.10793572190669012, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:17<00:00, 11.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 18, 'train_loss': 2.463993785381317, 'eval_loss': 2.450676245689392, 'train_ap_score': 0.10489269395757475, 'eval_ap_score': 0.10815301369839792, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 12.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 19, 'train_loss': 2.4635503947734834, 'eval_loss': 2.452676281929016, 'train_ap_score': 0.10515155550027591, 'eval_ap_score': 0.10787076755730811, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 11.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 20, 'train_loss': 2.4652561962604524, 'eval_loss': 2.4477973556518555, 'train_ap_score': 0.10461153758522541, 'eval_ap_score': 0.10811619056894617, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 12.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 21, 'train_loss': 2.4647561168670653, 'eval_loss': 2.4475809717178345, 'train_ap_score': 0.10479760529889917, 'eval_ap_score': 0.10809772002567722, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:17<00:00, 11.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 22, 'train_loss': 2.463616271018982, 'eval_loss': 2.452803988456726, 'train_ap_score': 0.10503731001662076, 'eval_ap_score': 0.1080260729665766, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 12.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 23, 'train_loss': 2.4633716487884523, 'eval_loss': 2.4496699810028075, 'train_ap_score': 0.10517804854281279, 'eval_ap_score': 0.10797488201864999, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 11.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 24, 'train_loss': 2.463193029165268, 'eval_loss': 2.449277300834656, 'train_ap_score': 0.10496978431590769, 'eval_ap_score': 0.10806247692695423, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 12.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 25, 'train_loss': 2.463753961324692, 'eval_loss': 2.448135027885437, 'train_ap_score': 0.10493573643761833, 'eval_ap_score': 0.10836595068647807, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 12.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 26, 'train_loss': 2.4642835903167724, 'eval_loss': 2.4499573564529418, 'train_ap_score': 0.10500237903098411, 'eval_ap_score': 0.10797503657151156, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:17<00:00, 11.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 27, 'train_loss': 2.463860375881195, 'eval_loss': 2.4490883636474607, 'train_ap_score': 0.10496424067867187, 'eval_ap_score': 0.10797468113006174, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 12.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 28, 'train_loss': 2.464039207696915, 'eval_loss': 2.4504351902008055, 'train_ap_score': 0.10499475985180391, 'eval_ap_score': 0.1078615982408659, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:17<00:00, 11.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 29, 'train_loss': 2.463043735027313, 'eval_loss': 2.452168650627136, 'train_ap_score': 0.10509584111227717, 'eval_ap_score': 0.1079631392462077, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 12.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 30, 'train_loss': 2.4638670921325683, 'eval_loss': 2.450228977203369, 'train_ap_score': 0.10480118999275782, 'eval_ap_score': 0.1082231438316688, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 11.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 31, 'train_loss': 2.464011716842651, 'eval_loss': 2.449205894470215, 'train_ap_score': 0.10468689850572525, 'eval_ap_score': 0.1083958330070596, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 12.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 32, 'train_loss': 2.4636079597473146, 'eval_loss': 2.448198928833008, 'train_ap_score': 0.10514433398056995, 'eval_ap_score': 0.10792045021959809, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 12.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 33, 'train_loss': 2.463630796670914, 'eval_loss': 2.4512928915023804, 'train_ap_score': 0.10518019735810898, 'eval_ap_score': 0.10819562238167543, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 12.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 34, 'train_loss': 2.464930305480957, 'eval_loss': 2.4523369121551513, 'train_ap_score': 0.10493750126819616, 'eval_ap_score': 0.10799055900140413, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 12.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 35, 'train_loss': 2.463846756219864, 'eval_loss': 2.4499032068252564, 'train_ap_score': 0.10510503956599324, 'eval_ap_score': 0.10799107306500069, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:17<00:00, 11.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 36, 'train_loss': 2.463838069438934, 'eval_loss': 2.448280987739563, 'train_ap_score': 0.10486057325770415, 'eval_ap_score': 0.10828568753721805, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:15<00:00, 12.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 37, 'train_loss': 2.4631851994991303, 'eval_loss': 2.4506756353378294, 'train_ap_score': 0.10485564040901037, 'eval_ap_score': 0.10824245352216129, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 11.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 38, 'train_loss': 2.4621990168094636, 'eval_loss': 2.452499279975891, 'train_ap_score': 0.10513007216410827, 'eval_ap_score': 0.10788896528331801, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:15<00:00, 12.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 39, 'train_loss': 2.4636429631710053, 'eval_loss': 2.4503595542907717, 'train_ap_score': 0.10485716900722386, 'eval_ap_score': 0.10813438989000154, 'lr': 0.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 200/200 [00:16<00:00, 12.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 40, 'train_loss': 2.463783495426178, 'eval_loss': 2.451315178871155, 'train_ap_score': 0.10477871113172336, 'eval_ap_score': 0.10843871482792089, 'lr': 0.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 4 (Optional)\n",
        "# This closes the active socket connection to wandb server. Optional since wandb destructor does the same.\n",
        "\n",
        "wandb.finish()\n",
        "\n",
        "### Step 4 ends.\n"
      ],
      "metadata": {
        "id": "JnQzf5xHOEKR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376,
          "referenced_widgets": [
            "05dcb1f21f9746ea8367494ce9d42f0d",
            "8ebdad85f47642b6ad3b08f08858677b",
            "537e98be367c40898dd99232c0ef9149",
            "af7399af35cf4f44aed5fad8744243c2",
            "ec17383bcc574ff78a3c99f32a08617d",
            "6d345c46c8114972b5cd66eaacb17fdb",
            "5a90ee45225840db82bc3b6e74667772",
            "3a0661fdf80c44f3b8790ea31aa3834e"
          ]
        },
        "outputId": "a714f58d-7e0b-4684-8972-8132e7b5213a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05dcb1f21f9746ea8367494ce9d42f0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>eval_ap_score</td><td>▅▄▅▆▇▅▄▄▆▄▄▅▇▅▆▁▄▆▄▆▅▅▄▅▇▄▄▄▄▆█▄▆▅▅▇▆▄▆█</td></tr><tr><td>eval_loss</td><td>▁▂▁▃▂▃█▄▅▆▃▅▃▅▆▅▇▄▆▁▁▆▃▃▂▃▂▄▅▃▃▂▄▅▃▂▄▅▄▄</td></tr><tr><td>lr</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_ap_score</td><td>▆▄▄▅▅▅█▆▄▃▃▆▂▄▆▅▅▄▆▁▃▅▆▄▄▅▄▅▆▃▂▆▆▄▆▃▃▆▃▃</td></tr><tr><td>train_loss</td><td>▃▄▄▂▄▄▁▃▅▇▆▂▆▃▄▃▄▅▄█▇▄▄▄▅▆▅▅▃▅▅▄▄▇▅▅▃▁▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>40</td></tr><tr><td>eval_ap_score</td><td>0.10844</td></tr><tr><td>eval_loss</td><td>2.45132</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>train_ap_score</td><td>0.10478</td></tr><tr><td>train_loss</td><td>2.46378</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">quiet-fog-13</strong> at: <a href='https://wandb.ai/dhruv_sri/wandb_demo/runs/09ddk26a' target=\"_blank\">https://wandb.ai/dhruv_sri/wandb_demo/runs/09ddk26a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230527_093047-09ddk26a/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-fQ5XateZfx3"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GY131mhVZfvc"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WandB sweeps related steps"
      ],
      "metadata": {
        "id": "UiUK11qqZQZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 1:\n",
        "# Create a WandB sweep config file.\n",
        "# This config file will be used at the WandB website to initialize a sweep server\n",
        "program: \"demo.py\"\n",
        "method: \"grid\"\n",
        "metric:\n",
        "  name: \"eval_ap_score\"\n",
        "  goal: \"maximize\"\n",
        "parameters:\n",
        "    criterion:\n",
        "      value: \"ce\"\n",
        "    gpu_id:\n",
        "      value: 0\n",
        "    lr:\n",
        "      values: [0.1, 0.001, 0.0001]\n",
        "    model_type:\n",
        "      values: [\"scratch\", \"pretrained\"]\n",
        "    num_epochs:\n",
        "      value: 25\n",
        "    optimizer:\n",
        "      values: [\"adam\", \"SGD\", \"RMSprop\"]\n",
        "    scheduler_patience:\n",
        "      value: 3\n",
        "    scheduler_thresh:\n",
        "      value: 0.01\n",
        "\n",
        "        \n",
        "### A sample sweep config file if bayes method is used-\n",
        "# program: wandb_demo.py\n",
        "# method: bayes\n",
        "# metric:\n",
        "#   name: \"eval_ap_score\"\n",
        "#   goal: maximize\n",
        "# parameters:\n",
        "#   lr:\n",
        "#     distribution: uniform\n",
        "#     min: 0.00001\n",
        "#     max: 0.1\n",
        "#   criterion:\n",
        "#     distribution: categorical\n",
        "#     value:\n",
        "#       - ce\n",
        "#   optimizer:\n",
        "#     distribution: categorical\n",
        "#     values:\n",
        "#       - adam\n",
        "#       - SGD\n",
        "#       - RMSprop\n",
        "#   model_type:\n",
        "#     distribution: categorical\n",
        "#     values:\n",
        "#       - pretrained\n",
        "#       - scratch\n",
        "#   num_epochs:\n",
        "#     value:\n",
        "#       - 30\n",
        "#   scheduler_thresh:\n",
        "#     distribution: uniform\n",
        "#     min: 0.001\n",
        "#     max: 0.01\n",
        "#   scheduler_patience:\n",
        "#     distribution: int_uniform\n",
        "#     min: 2\n",
        "#     max: 10\n"
      ],
      "metadata": {
        "id": "tMbRxfDwZT8r"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 2\n",
        "# After using the above config on wandb website, you will get a sweep id in return.\n",
        "# E.g. sweep id- dhruv_sri/wandb_demo/hbyp0tl8\n",
        "#\n",
        "# Add the following agent line in your code-\n",
        "# Use the generated sweep id in the below code\n",
        "\n",
        "wandb.agent(sweep_id=\"### FILL SWEEP ID HERE ###\", function=sweep_agent_manager, count=100)\n"
      ],
      "metadata": {
        "id": "8yEkgDnGZT2X"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 3\n",
        "# Notice in above command we mentioned an argument named \"function\"\n",
        "# Wandb agents must trigger a function where they can initiate a socket to wandb and get a config.\n",
        "# So, we will use the following sweep_agent_manager function here-\n",
        "\n",
        "def sweep_agent_manager():\n",
        "    wandb.init()\n",
        "    config = dict(wandb.config)\n",
        "    run_name = f\"{config['model_type']}_{config['optimizer']}_{config['lr']}\"\n",
        "    wandb.run.name = run_name\n",
        "    trigger_training(config)\n"
      ],
      "metadata": {
        "id": "bqY9TPyJZTx1"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Done.\n",
        "# Now execute your training script on multiple machines.\n",
        "# Each run will request the config file from wandb and related experiments will be logged.\n",
        "# \n",
        "# NOTE!! wandb.log(data_to_log) must be present inside the code!! Else there is no meaning to sweep.\n"
      ],
      "metadata": {
        "id": "alHqJ4mQZTtM"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ------------------------------ Ends ------------------------------"
      ],
      "metadata": {
        "id": "aNIxPqn_OGTU"
      }
    }
  ]
}